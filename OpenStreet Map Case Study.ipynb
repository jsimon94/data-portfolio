{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenStreetMap Data Case Study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map Area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Brooklyn, New York, USA\n",
    "\n",
    "Brooklyn is one of the five boroughs of New York City.\n",
    "\n",
    "* https://www.openstreetmap.org/node/158857828#map=13/40.6502/-73.9497\n",
    "* https://mapzen.com/data/metro-extracts/metro/brooklyn_new-york/\n",
    "\n",
    "Brooklyn is my hometown. I'm curious to see the contributions to the map so far, how messy the data is, and what we can reveal about the city via query. Also, I’d like to discuss an opportunity to contribute to its improvement on OpenStreetMap.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import collections\n",
    "import codecs\n",
    "import pprint\n",
    "import re\n",
    "import xml.etree.cElementTree as ET\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "brooklyn = \"brooklyn_new-york.osm\"  \n",
    "sample = \"sample.osm\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Audit\n",
    "I parse through the Brooklyn dataset with ElementTree and count the unique element type using the count_tags function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_element(osm_file):\n",
    "\tcontext = ET.iterparse(osm_file, events=('start', 'end'))\n",
    "\t_, root = next(context)\n",
    "\tfor event, elem in context:\n",
    "\t\tif event == 'end':\n",
    "\t\t\tyield elem\n",
    "\t\t\troot.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'member': 439,\n",
      " 'nd': 71496,\n",
      " 'node': 49947,\n",
      " 'osm': 1,\n",
      " 'relation': 42,\n",
      " 'tag': 56704,\n",
      " 'way': 9864}\n"
     ]
    }
   ],
   "source": [
    "def count_tags(osm_file):\n",
    "    tags = {}\n",
    "    for elem in get_element(osm_file):\n",
    "        if elem.tag in tags.keys():\n",
    "            tags[elem.tag] += 1\n",
    "        else:\n",
    "            tags[elem.tag] = 1\n",
    "        elem.clear()\n",
    "    return tags\n",
    "\n",
    "brooklyn_tags = count_tags(\"sample.osm\")\n",
    "pprint.pprint(brooklyn_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I check ‘k’ value for each tag. There are three regular expression, lower is for tags that contain only lowercase letters and are valid. lower_colon is for other valid tags with a colon in the value. problemchars is for tags with problematic characters. Finally I obtain a dictionary which contain the count of each of three tag categories above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'problemchars': 285, 'lower': 21426, 'other': 131, 'lower_colon': 34862}\n"
     ]
    }
   ],
   "source": [
    "lower = re.compile(r'^([a-z]|_)*$')\n",
    "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "\n",
    "def key_type(element, keys):\n",
    "    if element.tag == \"tag\":\n",
    "        if re.match(lower, element.attrib['k']):\n",
    "            keys[\"lower\"] += 1\n",
    "        elif re.match(lower_colon, element.attrib['k']):\n",
    "            keys[\"lower_colon\"] += 1\n",
    "        elif re.search(problemchars, element.attrib['k']):\n",
    "            keys[\"problemchars\"] += 1\n",
    "        else:\n",
    "            keys['other'] += 1\n",
    "    return keys\n",
    "\n",
    "\n",
    "def process_map(filename):\n",
    "    keys = {\"lower\": 0, \"lower_colon\": 0, \"problemchars\": 0, \"other\": 0}\n",
    "    for _, element in ET.iterparse(filename):\n",
    "        keys = key_type(element, keys)\n",
    "\n",
    "    return keys\n",
    "\n",
    "brooklyn_all_keys = process_map(\"sample.osm\")\n",
    "print brooklyn_all_keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problems Occured in the Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After initially downloading a small sample size of the Brooklyn area and running it against a provisional data.py file, I noticed five main problems with the data, which I will discuss in the following order:\n",
    "1. Abbreviated Street Names\n",
    "2. Misspelled Street Names\n",
    "3. \"Incorrect\" Postal Codes (Brooklyn area zip codes all begin with “112” however a large portion of all documented zip codes were outside this region).\n",
    "4. \"Incorrect\" Phone Numbers (Brooklyn phone numbers all begin with  \"718\" but a portion of all phone numbers were outside this region).\n",
    "5. Inconsistent Phone Numbers (+1-718-425-8769, 718) 235-0444,718-418-0793)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overabbreviated street names and Misspelled street names\n",
    "\n",
    "The first problem I encountered in this dataset is from the street name abbreviation. So build the regular expression to match the last element in the string, where usually the street type is based. Then based on the street abbreviation, create a mapping that need to be cleaned.\n",
    "\n",
    "Another problem in this dataset is misspelled street names like \"steet\" and \"avene\". Based on misspelled street names, create a mapping to that need to be corrected.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': set(['Avenue A']),\n",
      " 'Alley': set(['Cortlandt Alley', 'Grace Court Alley', 'Mac Dougal Alley']),\n",
      " 'Americas': set(['Avenue Of The Americas']),\n",
      " 'B': set(['Avenue B']),\n",
      " 'Bayside': set(['Bayside']),\n",
      " 'Bowery': set(['Bowery']),\n",
      " 'Broadway': set(['Broadway', 'East Broadway', 'West Broadway']),\n",
      " 'C': set(['Avenue C']),\n",
      " 'Crescent': set(['Boelsen Crescent',\n",
      "                  'Cromwell Crescent',\n",
      "                  'Dieterle Crescent',\n",
      "                  'Ellwell Crescent',\n",
      "                  'Slocum Crescent']),\n",
      " 'D': set(['Avenue D']),\n",
      " 'East': set(['Cadman Plaza East',\n",
      "              'Gramercy Park East',\n",
      "              'Village Road East',\n",
      "              'Williamsburg Street East']),\n",
      " 'Expressway': set(['Horace Harding Expressway']),\n",
      " 'F': set(['Avenue F']),\n",
      " 'H': set(['Avenue H']),\n",
      " 'Hamilton': set(['Fort Hamilton']),\n",
      " 'Heights': set(['Columbia Heights']),\n",
      " 'I': set(['Avenue I']),\n",
      " 'J': set(['Avenue J']),\n",
      " 'K': set(['Avenue K']),\n",
      " 'L': set(['Avenue L']),\n",
      " 'M': set(['Avenue M']),\n",
      " 'Mews': set(['Washington Mews']),\n",
      " 'N': set(['Avenue N']),\n",
      " 'North': set(['Barlow Drive North',\n",
      "               'Greenway North',\n",
      "               'Juniper Boulevard North',\n",
      "               'Paerdegat Avenue North',\n",
      "               'Queens Midtown Expressway Service Road North']),\n",
      " 'O': set(['Avenue O']),\n",
      " 'Oval': set(['Stuyvesant Oval']),\n",
      " 'P': set(['Avenue P']),\n",
      " 'R': set(['Avenue R']),\n",
      " 'Rico': set(['Avenue Of Puerto Rico']),\n",
      " 'Rockaways': set(['Hillside Avenue Rockaways']),\n",
      " 'S': set(['Avenue S']),\n",
      " 'Slip': set(['Rutgers Slip']),\n",
      " 'South': set(['Craig Road South',\n",
      "               'Juniper Boulevard South',\n",
      "               'Mayfair Drive South',\n",
      "               'Mc Guinness Boulevard South',\n",
      "               'Park Avenue South',\n",
      "               'Park Lane South',\n",
      "               'Queens Midtown Expressway Service Road South',\n",
      "               'Shore Parkway Sr South']),\n",
      " 'Southwest': set(['Prospect Park Southwest']),\n",
      " 'St': set(['1st St', 'Bloomfield St', 'Newark St']),\n",
      " 'T': set(['Avenue T']),\n",
      " 'Terrace': set(['56th Terrace',\n",
      "                 'Albemarle Terrace',\n",
      "                 'Barwell Terrace',\n",
      "                 'Bay Cliff Terrace',\n",
      "                 'Bliss Terrace',\n",
      "                 'Brighton 10th Terrace',\n",
      "                 'Brighton 4th Terrace',\n",
      "                 'Greenway Terrace',\n",
      "                 'Harbor View Terrace',\n",
      "                 'Park End Terrace',\n",
      "                 'Ridgecrest Terrace',\n",
      "                 'River Terrace',\n",
      "                 'Tudor Terrace',\n",
      "                 'Wogan Terrace']),\n",
      " 'Turnpike': set(['Union Turnpike']),\n",
      " 'U': set(['Avenue U']),\n",
      " 'V': set(['Avenue V']),\n",
      " 'W': set(['Avenue W']),\n",
      " 'West': set(['Grand Central Parkway Service Road West',\n",
      "              'Prospect Park West']),\n",
      " 'Willoughby': set(['Willoughby']),\n",
      " 'X': set(['Avenue X']),\n",
      " 'Y': set(['Avenue Y']),\n",
      " 'Z': set(['Avenue Z']),\n",
      " 'avenue': set(['Bedford avenue'])}\n"
     ]
    }
   ],
   "source": [
    "expected = [\"Street\", \"Avenue\", \"Boulevard\", \"Drive\", \"Court\", \"Place\", \"Highway\", \"Parkway\", \"Road\", \"Extension\",\n",
    "           \"Path\", \"Park\", \"Plaza\", \"Walk\", \"Square\", \"Piers\", \"Lane\", \"Center\"]\n",
    "\n",
    "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "\n",
    "def is_street_name(elem):\n",
    "    return (elem.attrib['k'] == \"addr:street\")\n",
    "\n",
    "def audit_street_type(street_types, street_name):\n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type not in expected:\n",
    "            street_types[street_type].add(street_name)\n",
    "            \n",
    "def audit_street(osmfile):\n",
    "\tosm_file = open(osmfile, \"r\")\n",
    "\tstreet_types = defaultdict(set)\n",
    "\tfor i, elem in enumerate(get_element(osmfile)):\n",
    "\t\tif elem.tag in [\"node\" ,\"way\"]:\n",
    "\t\t\tfor tag in elem.iter('tag'):\n",
    "\t\t\t\tif is_street_name(tag):\n",
    "\t\t\t\t\taudit_street_type(street_types, tag.attrib['v'])\n",
    "\tosm_file.close()\n",
    "\treturn street_types\n",
    "    \n",
    "bk_street_types = audit_street(sample)\n",
    "pprint.pprint(dict(bk_street_types))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mapping = { \"Ave\":\"Avenue\",\n",
    "            \"Ave.\":\"Avenue\",\n",
    "            \"ave\":\"Avenue\",\n",
    "            \"Avene\":\"Avenue\",\n",
    "            \"avenue\":\"Avenue\",\n",
    "            \"Blvd\":\"Boulevard\",\n",
    "            \"Ctr\":\"Center\",\n",
    "            \"Dr\":\"Drive\",\n",
    "            \"Plz\":\"Plaza\",\n",
    "            \"Rd\":\"Road\",\n",
    "            \"St\":\"Street\",\n",
    "            \"St.\":\"Street\",\n",
    "            \"ST\":\"Street\"\n",
    "            }\n",
    "\n",
    "def update_name(name, mapping):\n",
    "    '''Cleans name for insertion into database.'''\n",
    "    m = street_type_re.search(name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type not in expected:\n",
    "            if street_type in mapping.keys():\n",
    "                name = re.sub(street_type_re, mapping[street_type], name)\n",
    "    return name\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bayside => Bayside\n",
      "Grand Central Parkway Service Road West => Grand Central Parkway Service Road West\n",
      "Prospect Park West => Prospect Park West\n",
      "Columbia Heights => Columbia Heights\n",
      "Union Turnpike => Union Turnpike\n",
      "Avenue Of Puerto Rico => Avenue Of Puerto Rico\n",
      "Avenue X => Avenue X\n",
      "Village Road East => Village Road East\n",
      "Cadman Plaza East => Cadman Plaza East\n",
      "Williamsburg Street East => Williamsburg Street East\n",
      "Gramercy Park East => Gramercy Park East\n",
      "Bedford avenue => Bedford Avenue\n",
      "Prospect Park Southwest => Prospect Park Southwest\n",
      "Horace Harding Expressway => Horace Harding Expressway\n",
      "Juniper Boulevard North => Juniper Boulevard North\n",
      "Barlow Drive North => Barlow Drive North\n",
      "Paerdegat Avenue North => Paerdegat Avenue North\n",
      "Greenway North => Greenway North\n",
      "Queens Midtown Expressway Service Road North => Queens Midtown Expressway Service Road North\n",
      "Bowery => Bowery\n",
      "Willoughby => Willoughby\n",
      "Fort Hamilton => Fort Hamilton\n",
      "Boelsen Crescent => Boelsen Crescent\n",
      "Dieterle Crescent => Dieterle Crescent\n",
      "Slocum Crescent => Slocum Crescent\n",
      "Ellwell Crescent => Ellwell Crescent\n",
      "Cromwell Crescent => Cromwell Crescent\n",
      "Avenue A => Avenue A\n",
      "Avenue C => Avenue C\n",
      "Avenue B => Avenue B\n",
      "Avenue D => Avenue D\n",
      "Avenue F => Avenue F\n",
      "Avenue I => Avenue I\n",
      "Avenue H => Avenue H\n",
      "Avenue K => Avenue K\n",
      "Avenue J => Avenue J\n",
      "Avenue M => Avenue M\n",
      "Avenue L => Avenue L\n",
      "Avenue O => Avenue O\n",
      "Newark St => Newark Street\n",
      "Bloomfield St => Bloomfield Street\n",
      "1st St => 1st Street\n",
      "Avenue P => Avenue P\n",
      "Avenue S => Avenue S\n",
      "Avenue R => Avenue R\n",
      "Avenue U => Avenue U\n",
      "Avenue T => Avenue T\n",
      "Avenue W => Avenue W\n",
      "Avenue V => Avenue V\n",
      "Avenue Y => Avenue Y\n",
      "Washington Mews => Washington Mews\n",
      "Avenue Of The Americas => Avenue Of The Americas\n",
      "Queens Midtown Expressway Service Road South => Queens Midtown Expressway Service Road South\n",
      "Park Avenue South => Park Avenue South\n",
      "Park Lane South => Park Lane South\n",
      "Craig Road South => Craig Road South\n",
      "Shore Parkway Sr South => Shore Parkway Sr South\n",
      "Mc Guinness Boulevard South => Mc Guinness Boulevard South\n",
      "Juniper Boulevard South => Juniper Boulevard South\n",
      "Mayfair Drive South => Mayfair Drive South\n",
      "Avenue Z => Avenue Z\n",
      "Mac Dougal Alley => Mac Dougal Alley\n",
      "Cortlandt Alley => Cortlandt Alley\n",
      "Grace Court Alley => Grace Court Alley\n",
      "Avenue N => Avenue N\n",
      "River Terrace => River Terrace\n",
      "Ridgecrest Terrace => Ridgecrest Terrace\n",
      "Tudor Terrace => Tudor Terrace\n",
      "Park End Terrace => Park End Terrace\n",
      "Brighton 4th Terrace => Brighton 4th Terrace\n",
      "Harbor View Terrace => Harbor View Terrace\n",
      "Bay Cliff Terrace => Bay Cliff Terrace\n",
      "Barwell Terrace => Barwell Terrace\n",
      "Wogan Terrace => Wogan Terrace\n",
      "Brighton 10th Terrace => Brighton 10th Terrace\n",
      "56th Terrace => 56th Terrace\n",
      "Bliss Terrace => Bliss Terrace\n",
      "Albemarle Terrace => Albemarle Terrace\n",
      "Greenway Terrace => Greenway Terrace\n",
      "Rutgers Slip => Rutgers Slip\n",
      "Stuyvesant Oval => Stuyvesant Oval\n",
      "Broadway => Broadway\n",
      "West Broadway => West Broadway\n",
      "East Broadway => East Broadway\n",
      "Hillside Avenue Rockaways => Hillside Avenue Rockaways\n"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "    st_types = audit_street(sample)\n",
    "    #assert len(st_types) == 3\n",
    "    #pprint.pprint(dict(st_types))\n",
    "    for st_type, ways in st_types.iteritems():\n",
    "        for name in ways:\n",
    "            better_name = update_name(name, mapping)\n",
    "            print name, \"=>\", better_name\n",
    "if __name__ == '__main__':\n",
    "    test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"Incorrect\" zipcodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The zipcode of Brooklyn begin with “112”, we modified the functions before and check zipcode. From the result we can see most of the zip code format (5 digits in length) is correct, but there is a significant portion of zipcodes that don't belong in Brooklyn. For example, zipcodes like 07030 is from New Jersey and 10003 is from Manhattan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'070': set(['07030']),\n",
      " '073': set(['07302']),\n",
      " '100': set(['10002',\n",
      "             '10003',\n",
      "             '10004',\n",
      "             '10005',\n",
      "             '10006',\n",
      "             '10007',\n",
      "             '10009',\n",
      "             '10010',\n",
      "             '10011',\n",
      "             '10012',\n",
      "             '10013',\n",
      "             '10014',\n",
      "             '10038']),\n",
      " '102': set(['10282']),\n",
      " '111': set(['11101', '11104']),\n",
      " '112': set(['11201',\n",
      "             '11203',\n",
      "             '11204',\n",
      "             '11205',\n",
      "             '11206',\n",
      "             '11207',\n",
      "             '11208',\n",
      "             '11209',\n",
      "             '11210',\n",
      "             '11211',\n",
      "             '11212',\n",
      "             '11213',\n",
      "             '11214',\n",
      "             '11215',\n",
      "             '11215-9993',\n",
      "             '11216',\n",
      "             '11217',\n",
      "             '11218',\n",
      "             '11219',\n",
      "             '11220',\n",
      "             '11221',\n",
      "             '11222',\n",
      "             '11223',\n",
      "             '11224',\n",
      "             '11225',\n",
      "             '11226',\n",
      "             '11228',\n",
      "             '11229',\n",
      "             '11230',\n",
      "             '11231',\n",
      "             '11232',\n",
      "             '11233',\n",
      "             '11234',\n",
      "             '11235',\n",
      "             '11236',\n",
      "             '11237',\n",
      "             '11238',\n",
      "             '11239',\n",
      "             '11249']),\n",
      " '113': set(['11367',\n",
      "             '11368',\n",
      "             '11373',\n",
      "             '11374',\n",
      "             '11375',\n",
      "             '11377',\n",
      "             '11378',\n",
      "             '11379',\n",
      "             '11385']),\n",
      " '114': set(['11414', '11415', '11416', '11417', '11418', '11419', '11421']),\n",
      " '116': set(['11694', '11697'])}\n"
     ]
    }
   ],
   "source": [
    "def audit_zipcode(invalid_zipcodes, zipcode):\n",
    "    '''Returns zipcodes that are not in the area in the osm file.'''\n",
    "    threeDigits = zipcode[0:3]\n",
    "    if threeDigits != 112 or not threeDigits.isdigit():\n",
    "        invalid_zipcodes[threeDigits].add(zipcode)\n",
    "        \n",
    "def is_zipcode(elem):\n",
    "    return (elem.attrib['k'] == \"addr:postcode\")\n",
    "\n",
    "def audit_zip(osmfile):\n",
    "    '''Returns a dictionary of zipcodes in the osm file'''\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    invalid_zipcodes = collections.defaultdict(set)\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_zipcode(tag):\n",
    "                    audit_zipcode(invalid_zipcodes,tag.attrib['v'])\n",
    "\n",
    "    return invalid_zipcodes\n",
    "\n",
    "bk_zipcode = audit_zip(sample)\n",
    "pprint.pprint(dict(bk_zipcode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07302 => 07302\n",
      "07030 => 07030\n",
      "11414 => 11414\n",
      "11415 => 11415\n",
      "11416 => 11416\n",
      "11417 => 11417\n",
      "11418 => 11418\n",
      "11419 => 11419\n",
      "11421 => 11421\n",
      "11697 => 11697\n",
      "11694 => 11694\n",
      "11101 => 11101\n",
      "11104 => 11104\n",
      "11379 => 11379\n",
      "11385 => 11385\n",
      "11368 => 11368\n",
      "11375 => 11375\n",
      "11374 => 11374\n",
      "11377 => 11377\n",
      "11373 => 11373\n",
      "11367 => 11367\n",
      "11378 => 11378\n",
      "11207 => 11207\n",
      "11228 => 11228\n",
      "11201 => 11201\n",
      "11203 => 11203\n",
      "11205 => 11205\n",
      "11204 => 11204\n",
      "11229 => 11229\n",
      "11226 => 11226\n",
      "11209 => 11209\n",
      "11208 => 11208\n",
      "11225 => 11225\n",
      "11224 => 11224\n",
      "11223 => 11223\n",
      "11218 => 11218\n",
      "11221 => 11221\n",
      "11220 => 11220\n",
      "11219 => 11219\n",
      "11249 => 11249\n",
      "11215-9993 => 11215\n",
      "11222 => 11222\n",
      "11206 => 11206\n",
      "11238 => 11238\n",
      "11213 => 11213\n",
      "11210 => 11210\n",
      "11211 => 11211\n",
      "11216 => 11216\n",
      "11217 => 11217\n",
      "11214 => 11214\n",
      "11215 => 11215\n",
      "11230 => 11230\n",
      "11231 => 11231\n",
      "11232 => 11232\n",
      "11233 => 11233\n",
      "11234 => 11234\n",
      "11235 => 11235\n",
      "11236 => 11236\n",
      "11237 => 11237\n",
      "11212 => 11212\n",
      "11239 => 11239\n",
      "10282 => 10282\n",
      "10004 => 10004\n",
      "10005 => 10005\n",
      "10006 => 10006\n",
      "10007 => 10007\n",
      "10002 => 10002\n",
      "10003 => 10003\n",
      "10009 => 10009\n",
      "10038 => 10038\n",
      "10013 => 10013\n",
      "10012 => 10012\n",
      "10011 => 10011\n",
      "10010 => 10010\n",
      "10014 => 10014\n"
     ]
    }
   ],
   "source": [
    "def update_postcode(postcode):\n",
    "    '''Returns 5 digit postcodes for insertion into SQL Database'''\n",
    "    search = re.match(r'^\\D*(\\d{5}).*', postcode)\n",
    "    clean_postcode = search.group(1)\n",
    "    return clean_postcode\n",
    "\n",
    "for st_type, ways in bk_zipcode.iteritems():\n",
    "        for name in ways:\n",
    "            better_name = update_postcode(name)\n",
    "            print name, \"=>\", better_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"Incorrect\" and Inconsistent phone numbers\n",
    "\n",
    "Change the format of all phone numbers to (###) ###-####. Brooklyn phone area code is 718. Note that a portion of the phone numbers with the area code of 212 is from Manhattan and phone numbers with the area 201 is from New Jersey."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set(['(212) 228-2004',\n",
      "     '(212) 260-1175',\n",
      "     '(212) 465-0880',\n",
      "     '(212) 995-2020',\n",
      "     '(718) 488-7005',\n",
      "     '(718) 520-5444',\n",
      "     '(718) 677-5811',\n",
      "     '(718) 768-6868',\n",
      "     '+1 212 254 1508',\n",
      "     '+1 212 255-7260',\n",
      "     '+1 212 691 1287',\n",
      "     '+1 718 788-0050',\n",
      "     '+1 844 359 2523',\n",
      "     '+1-212-510-8551',\n",
      "     '+1-718.436.0545',\n",
      "     '+17188527800',\n",
      "     '201 216-1766',\n",
      "     '212-219-8787',\n",
      "     '718 349 6020',\n",
      "     '718 349 6555',\n",
      "     '718 389 6965',\n",
      "     '718) 235-0444',\n",
      "     '718-418-0793',\n",
      "     '7183993696'])\n"
     ]
    }
   ],
   "source": [
    "def is_phone(elem):\n",
    "    '''Search elements that have phone numbers.'''\n",
    "    return(elem.tag == 'tag') and (elem.attrib['k'] == \"phone\" or elem.atrrib['k']=='fax')\n",
    "\n",
    "def phone_numbers(osmfile):\n",
    "    '''Takes phone numbers from osm file and output a set of phone numbers'''\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    phone_nums = set()\n",
    "    for event, elem in ET.iterparse(osmfile):\n",
    "        if elem.tag in [\"node\" ,\"way\"]:\n",
    "             for tag in elem.iter(\"tag\"):\n",
    "                if tag.attrib['k'] == \"phone\":\n",
    "                    phone_nums.add(tag.attrib['v'])\n",
    "    return phone_nums\n",
    "                    \n",
    "bk_phone = phone_numbers(\"sample.osm\")\n",
    "pprint.pprint(bk_phone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(718) 235-0444\n",
      "(212) 260-1175\n",
      "(718) 389-6965\n",
      "(718) 488-7005\n",
      "(718) 520-5444\n",
      "(212) 254-1508\n",
      "(212) 510-8551\n",
      "(212) 228-2004\n",
      "(212) 465-0880\n",
      "(718) 852-7800\n",
      "(212) 219-8787\n",
      "(718) 349-6555\n",
      "(718) 399-3696\n",
      "(212) 691-1287\n",
      "(718) 349-6020\n",
      "(718) 418-0793\n",
      "(844) 359-2523\n",
      "(718) 768-6868\n",
      "(718) 788-0050\n",
      "(718) 436-0545\n",
      "(718) 677-5811\n",
      "(212) 255-7260\n",
      "(201) 216-1766\n",
      "(212) 995-2020\n"
     ]
    }
   ],
   "source": [
    "PHONENUM = re.compile(r'^\\(\\d{3}\\)\\s\\d{3}-\\d{4}$')\n",
    "\n",
    "def update_phone(phone_num):\n",
    "    '''Cleans phone number for insertion into SQL Database.'''\n",
    "    if isinstance(phone_num, str):\n",
    "        #Check for valid number format.\n",
    "        m = PHONENUM.search(phone_num)\n",
    "        if m is None:\n",
    "            #Removes \"+1-\n",
    "            if phone_num.startswith('+1-'):\n",
    "                phone_num = phone_num.replace('+1-','')\n",
    "            #Removes +1\n",
    "            if \"+1\" in phone_num:\n",
    "                phone_num = phone_num.replace('+1','')\n",
    "            #Removes '.' that were contained in phonenumbers\n",
    "            if \".\" in phone_num:\n",
    "                phone_num = phone_num.replace(\".\", \"\")\n",
    "            #Removes dashes\n",
    "            if \"-\" in phone_num:\n",
    "                phone_num = re.sub(\"-\", \"\", phone_num)\n",
    "            #Removes brackets and parenthesis\n",
    "            if \"(\" in phone_num or \")\" in phone_num:\n",
    "                phone_num = re.sub(\"[()]\", \"\", phone_num)\n",
    "            #Remove spaces inbetween digits of the phone number\n",
    "            if \" \" in phone_num:\n",
    "                phone_num = re.sub(\" \", \"\", phone_num)\n",
    "            #Format the phone numbers into (718) 123-4567 format.\n",
    "            if re.match(r'\\d{10}', phone_num) is not None:\n",
    "                phone_num = \"(\" + phone_num[:3] + \")\" + \" \"+ phone_num[3:6] + \"-\" + phone_num[6:]\n",
    "        return phone_num\n",
    "    \n",
    "for phone_num in bk_phone:\n",
    "    print update_phone(phone_num)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import csv\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sqlite_file = 'bklyn.db'    # name of the sqlite database file\n",
    "\n",
    "# Connect to the database\n",
    "conn = sqlite3.connect(sqlite_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get a cursor object\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(49947,)]\n"
     ]
    }
   ],
   "source": [
    "cur.execute('SELECT COUNT(*) FROM Nodes')\n",
    "all_rows = cur.fetchall()\n",
    "print(all_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(9864,)]\n"
     ]
    }
   ],
   "source": [
    "cur.execute('SELECT COUNT(*) FROM Ways')\n",
    "all_rows = cur.fetchall()\n",
    "print(all_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Unique Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(436,)]\n"
     ]
    }
   ],
   "source": [
    "cur.execute('SELECT COUNT(DISTINCT(e.uid)) FROM (SELECT uid FROM nodes UNION ALL SELECT uid FROM ways) e;')\n",
    "all_rows = cur.fetchall()\n",
    "print(all_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 10 Contributing Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'Rub21_nycbuildings', 34778),\n",
      " (u'ingalls_nycbuildings', 7497),\n",
      " (u'ediyes_nycbuildings', 3786),\n",
      " (u'celosia_nycbuildings', 2337),\n",
      " (u'ingalls', 2118),\n",
      " (u'lxbarth_nycbuildings', 1606),\n",
      " (u'aaron_nycbuildings', 811),\n",
      " (u'ewedistrict_nycbuildings', 694),\n",
      " (u'smlevine', 501),\n",
      " (u'robgeb', 487)]\n"
     ]
    }
   ],
   "source": [
    "cur.execute('SELECT e.user, COUNT(*) as num FROM (SELECT user FROM nodes UNION ALL SELECT user FROM ways) e GROUP BY e.user ORDER BY num DESC LIMIT 10;')\n",
    "top_ten = cur.fetchall()\n",
    "pprint(top_ten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Unique Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(436,)]\n"
     ]
    }
   ],
   "source": [
    "cur.execute(\"SELECT COUNT(DISTINCT(e.uid)) FROM \\\n",
    "          (SELECT uid FROM nodes UNION ALL SELECT uid FROM ways) e;\")\n",
    "print cur.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 10 Amenities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'bicycle_parking', 59),\n",
      " (u'restaurant', 15),\n",
      " (u'cafe', 10),\n",
      " (u'school', 10),\n",
      " (u'bar', 6),\n",
      " (u'bicycle_rental', 5),\n",
      " (u'fast_food', 5),\n",
      " (u'place_of_worship', 5),\n",
      " (u'bench', 4),\n",
      " (u'post_office', 3)]\n"
     ]
    }
   ],
   "source": [
    "cur.execute(\"SELECT value, COUNT(*) as num \\\n",
    "            FROM NodesTags \\\n",
    "           WHERE key='amenity' \\\n",
    "           GROUP BY value \\\n",
    "           ORDER BY num DESC \\\n",
    "           LIMIT 10;\")\n",
    "\n",
    "pprint(cur.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'pizza', 2),\n",
      " (u'Southern', 1),\n",
      " (u'diner', 1),\n",
      " (u'italian', 1),\n",
      " (u'ramen', 1),\n",
      " (u'soul_food', 1)]\n"
     ]
    }
   ],
   "source": [
    "cur.execute(\"SELECT NodesTags.value, COUNT(*) as num \\\n",
    "           FROM NodesTags \\\n",
    "               JOIN (SELECT DISTINCT(id) FROM NodesTags WHERE value = 'restaurant') \\\n",
    "               i ON NodesTags.id = i.id \\\n",
    "           WHERE NodesTags.key = 'cuisine'\\\n",
    "           GROUP BY NodesTags.value\\\n",
    "           ORDER BY num DESC;\")\n",
    "\n",
    "pprint(cur.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the process of auditing we can see the dataset is not very well-cleaned even though there are alot of data outside of the brooklyn such as postal codes, phone numbers and street names. Since there are thousands of contributing users, so it is inevitable to have so many human input error. My thought is: is it possible to create a monitor system to check everybody’s contribution regularly. Another thought is to put a rough GPS data processor in place and working together with a more robust data processor similar to data.py. That way all the info of the area will be in the dataset. I think it would be possible to input a great amount of cleaned data to OpenStreetMap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:DAND]",
   "language": "python",
   "name": "conda-env-DAND-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
